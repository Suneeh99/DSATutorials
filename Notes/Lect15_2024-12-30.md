# Heap Tree

A **heap tree** is a complete binary tree where every level, except possibly the last, is fully filled. The key property of a heap is that it is ordered. There are two types of heaps: **Max-Heap** and **Min-Heap**.

### Heap Properties

1. **Max-Heap**:
    - In a max-heap, the value of each node is greater than or equal to the values of its children. This property must hold true for every node, excluding the root.
    - The largest element is always at the root of the tree.
    - Example: If `A[Parent[i]] >= A[i]`, then the heap property is satisfied.
2. **Min-Heap**:
    - In a min-heap, the value of each node is less than or equal to the values of its children.
    - The smallest element is always at the root of the tree.

### Heap Tree Example

Consider the following max-heap tree representation:

```
          24
        /    \
      21      23
     /  \    /   \
   22   36  29    30
  /  \  /  
34  28 27 
```

Here:

- The root node (24) is the largest value in the heap.
- The tree is a complete binary tree.
- The property of the max-heap holds as the value of every parent node is greater than or equal to its children.

---

### Build a Max-Heap

To **build a max-heap** from an unordered array, we can perform a **heapify** operation. This is done by starting from the last non-leaf node and performing the max-heapify operation recursively for each node until the heap property is satisfied.

### Procedure: MaxHeapify

The **MaxHeapify** procedure ensures that the max-heap property is maintained for a given node and its children.

#### MaxHeapify Algorithm:

```md
MaxHeapify(A, i)
1. l = left(i)    // Left child index of node i
2. r = right(i)   // Right child index of node i
3. if l <= heap-size(A) and A[l] > A[i]   // If left child is larger than the current node
4. then largest ← l
5. else largest ← i
6. if r <= heap-size(A) and A[r] > A[largest]  // If right child is larger than the largest of the left and current node
7. then largest ← r
8. if largest ≠ i    // If the largest value is not the current node
9. then swap A[i] ↔ A[largest]    // Swap the values of the current node and the largest node
10. MaxHeapify(A, largest)    // Recursively call MaxHeapify on the affected subtree
```

This algorithm ensures that the max-heap property is maintained by repeatedly adjusting the tree.

---

### Time Complexity of Heap Operations

The time complexity of heap operations depends on the number of levels in the tree and the number of elements in the heap.

1. **MaxHeapify**:
    
    - The height of a heap is `O(log n)`, where `n` is the number of nodes.
    - At each level, a constant amount of work (comparison and possible swap) is done.
    - Therefore, the time complexity of **MaxHeapify** is `O(log n)`.
2. **Build Max-Heap**:
    
    - The process of building a max-heap involves calling `MaxHeapify` on each node, starting from the last non-leaf node.
    - The time complexity for building the max-heap is `O(n)`, since the work done at each level decreases as you move up the tree.
3. **Insertion**:
    
    - Insertion into a heap involves adding a new element at the end of the tree and "bubbling up" to maintain the heap property.
    - The time complexity for insertion is `O(log n)` because the height of the heap is `O(log n)` and each insertion involves at most one comparison per level.
4. **Deletion (Remove Max)**:
    
    - Deleting the maximum element (root) involves replacing it with the last element, followed by a "heapify down" operation to restore the heap property.
    - The time complexity for deletion is `O(log n)`.

---

### Time Complexity Notations

When analyzing the time complexity of algorithms, we use several notations:

1. **Big O Notation (O)**:
    
    - Represents the **upper bound** of an algorithm's time or space complexity.
    - It describes the worst-case scenario: the maximum amount of time or space an algorithm will require.
    - Example: For an algorithm with a time complexity of `O(n^2)`, the execution time will grow at most proportionally to the square of the input size.
2. **Big Omega Notation (Ω)**:
    
    - Represents the **lower bound** of an algorithm's time or space complexity.
    - It describes the best-case scenario: the minimum time or space an algorithm will need to solve a problem.
    - Example: For an algorithm with a time complexity of `Ω(n)`, the execution time will grow at least proportionally to the input size.
3. **Big Theta Notation (Θ)**:
    
    - Represents the **tight bound** of an algorithm's time or space complexity.
    - It describes the **average case** and shows both the upper and lower bounds.
    - Example: If an algorithm has a time complexity of `Θ(n^2)`, it means that the time taken will grow at the same rate as `n^2` in both the best and worst cases.

### Example

For an algorithm with time complexity `2π^2 + 3n + 1`:

- The term `2π^2` is a constant, and constants are ignored in big-O notation.
- The term `3n` represents a linear growth rate.
- The highest order term is `n^2`, which determines the overall time complexity.
- Therefore, the time complexity is `O(n^2)`.
